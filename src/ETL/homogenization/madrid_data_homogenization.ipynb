{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: pd.DataFrame):\n",
    "    # Crear la columna de fecha\n",
    "    # df['Fecha'] = pd.to_datetime(df[['ANO', 'MES', 'DIA']], format='YYYY-MM-DD')\n",
    "\n",
    "    df = df.rename(columns={'ANO': 'year', 'MES': 'month', 'DIA': 'day'})\n",
    "    \n",
    "    # Crear la columna de fecha correctamente\n",
    "    df['Fecha'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "    # Filtrar las columnas de horas\n",
    "    columnas_horas = [col for col in df.columns if col.startswith('H')]\n",
    "\n",
    "    # Convertir el formato a filas\n",
    "    df_melted = df.melt(id_vars=['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO', 'Fecha'], \n",
    "                        value_vars=columnas_horas, \n",
    "                        var_name='Hora', \n",
    "                        value_name='Valor')\n",
    "\n",
    "    # Convertir la columna 'Hora' a número de hora\n",
    "    df_melted['Hora'] = df_melted['Hora'].str[1:].astype(int) - 1  # Eliminar 'H' y ajustar a formato de 24h\n",
    "    return df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_data(df: pd.DataFrame):\n",
    "    fecha = pd.to_datetime(df['Fecha']).agg()    \n",
    "    # Crear la columna de fecha correctamente\n",
    "    df['Fecha'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "    # Filtrar las columnas de horas\n",
    "    columnas_horas = [col for col in df.columns if col.startswith('H')]\n",
    "\n",
    "    # Convertir el formato a filas\n",
    "    df_melted = df.melt(id_vars=['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'MAGNITUD', 'PUNTO_MUESTREO', 'Fecha'], \n",
    "                        value_vars=columnas_horas, \n",
    "                        var_name='Hora', \n",
    "                        value_name='Valor')\n",
    "\n",
    "    # Convertir la columna 'Hora' a número de hora\n",
    "    df_melted['Hora'] = df_melted['Hora'].str[1:].astype(int) - 1  # Eliminar 'H' y ajustar a formato de 24h\n",
    "    return df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = '../../../data/raw/madrid_data/horarios'\n",
    "meses = ['ene', 'feb', 'mar', 'may', 'jun', 'jul', 'ago', 'sep', 'oct', 'nov', 'dic']\n",
    "anhos = ['19', '20', '21', '22', '23', '24', '25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/ene_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/feb_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/mar_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/may_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/jun_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/jul_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/ago_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/sep_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/oct_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/nov_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2019/dic_meteo19.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/ene_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/feb_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/mar_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/may_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/jun_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/jul_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/ago_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/sep_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/oct_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/nov_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2020/dic_meteo20.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/ene_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/feb_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/mar_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/may_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/jun_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/jul_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/ago_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/sep_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/oct_meteo21.csv\n",
      "ASD\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2021/oct_meteo21.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2021/oct_meteo21.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/nov_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2021/dic_meteo21.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/ene_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/feb_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/mar_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/may_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/jun_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/jul_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/ago_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/sep_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/oct_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/nov_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2022/dic_meteo22.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/ene_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/feb_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/mar_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/may_meteo23.csv\n",
      "ASD\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2023/may_meteo23.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2023/may_meteo23.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/jun_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/jul_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/ago_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/sep_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/oct_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/nov_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2023/dic_meteo23.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/ene_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/feb_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/mar_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/may_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/jun_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/jul_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/ago_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/sep_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/oct_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/nov_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2024/dic_meteo24.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/ene_meteo25.csv\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/feb_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/feb_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/feb_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/mar_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/mar_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/mar_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/may_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/may_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/may_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/jun_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/jun_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/jun_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/jul_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/jul_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/jul_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/ago_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/ago_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/ago_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/sep_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/sep_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/sep_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/oct_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/oct_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/oct_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/nov_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/nov_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/nov_meteo25.csv'\n",
      "Procesando: ../../../data/raw/madrid_data/horarios/2025/dic_meteo25.csv\n",
      "❌ ERROR al procesar ../../../data/raw/madrid_data/horarios/2025/dic_meteo25.csv: [Errno 2] No such file or directory: '../../../data/raw/madrid_data/horarios/2025/dic_meteo25.csv'\n"
     ]
    }
   ],
   "source": [
    "lista_dfs = []\n",
    "\n",
    "for anho in anhos:\n",
    "    for mes in meses:\n",
    "        try:\n",
    "            file = f'{ruta}/20{anho}/{mes}_meteo{anho}.csv'\n",
    "            print(f\"Procesando: {file}\")\n",
    "            df = pd.read_csv(file, sep=';')\n",
    "\n",
    "            # Verificar si el DataFrame tiene datos\n",
    "            if df.empty:\n",
    "                print(f\"⚠️ Archivo vacío: {file}\")\n",
    "                continue  # Saltar al siguiente archivo\n",
    "\n",
    "            # Transformar los datos\n",
    "            df_transformado = transform_data(df)\n",
    "\n",
    "            # Verificar si la transformación devuelve un DataFrame válido\n",
    "            if isinstance(df_transformado, pd.DataFrame):\n",
    "                lista_dfs.append(df_transformado)  # Agregar a la lista\n",
    "            else:\n",
    "                print(f\"⚠️ Error en la transformación del archivo: {file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if anho != '25':\n",
    "                print(f\"❌ ERROR al procesar {file}: {e}\")\n",
    "                # Intentar obtener datos del año anterior y posterior\n",
    "                try:\n",
    "                    anho_ant = str(int(anho) - 1).zfill(2)\n",
    "                    anho_sig = str(int(anho) + 1).zfill(2)\n",
    "\n",
    "                    file_ant = f'{ruta}/20{anho_ant}/{mes}_meteo{anho_ant}.csv'\n",
    "                    file_sig = f'{ruta}/20{anho_sig}/{mes}_meteo{anho_sig}.csv'\n",
    "\n",
    "                    df_ant = pd.read_csv(file_ant, sep=';')\n",
    "                    df_sig = pd.read_csv(file_sig, sep=';')\n",
    "\n",
    "                    if not df_ant.empty and not df_sig.empty:\n",
    "                        df_ant_trans = transform_data(df_ant)\n",
    "                        df_sig_trans = transform_data(df_sig)\n",
    "\n",
    "                        df_ant_trans['']\n",
    "                        \n",
    "                        if isinstance(df_transformado, pd.DataFrame):\n",
    "                            lista_dfs.append(df_transformado)\n",
    "                        else:\n",
    "                            print(f\"⚠️ Error en la transformación de la media para {file}\")\n",
    "                    else:\n",
    "                        print(f\"⚠️ No se encontraron datos para calcular la media en {anho_ant} y {anho_sig}\")\n",
    "\n",
    "                except Exception as e2:\n",
    "                    print(f\"❌ ERROR al intentar calcular la media con años adyacentes para {file}: {e2}\")\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "if lista_dfs:\n",
    "    datos = pd.concat(lista_dfs, ignore_index=True)\n",
    "else:\n",
    "    print(\"⚠️ No se pudo cargar ningún archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>81</td>\n",
       "      <td>28079102_81_98</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>82</td>\n",
       "      <td>28079102_82_98</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>83</td>\n",
       "      <td>28079102_83_98</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>28079102_86_98</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>87</td>\n",
       "      <td>28079102_87_98</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>949.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120171</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>59</td>\n",
       "      <td>83</td>\n",
       "      <td>28079059_83_98</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>23</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120202</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>28079059_86_98</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>23</td>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120233</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>59</td>\n",
       "      <td>87</td>\n",
       "      <td>28079059_87_98</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>23</td>\n",
       "      <td>948.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120264</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>28079059_88_98</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>23</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120295</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>59</td>\n",
       "      <td>89</td>\n",
       "      <td>28079059_89_98</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>23</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4120296 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD  PUNTO_MUESTREO      Fecha  \\\n",
       "0               28         79       102        81  28079102_81_98 2019-01-01   \n",
       "31              28         79       102        82  28079102_82_98 2019-01-01   \n",
       "62              28         79       102        83  28079102_83_98 2019-01-01   \n",
       "93              28         79       102        86  28079102_86_98 2019-01-01   \n",
       "124             28         79       102        87  28079102_87_98 2019-01-01   \n",
       "...            ...        ...       ...       ...             ...        ...   \n",
       "4120171         28         79        59        83  28079059_83_98 2025-01-31   \n",
       "4120202         28         79        59        86  28079059_86_98 2025-01-31   \n",
       "4120233         28         79        59        87  28079059_87_98 2025-01-31   \n",
       "4120264         28         79        59        88  28079059_88_98 2025-01-31   \n",
       "4120295         28         79        59        89  28079059_89_98 2025-01-31   \n",
       "\n",
       "         Hora   Valor  \n",
       "0           0    0.65  \n",
       "31          0   64.00  \n",
       "62          0    3.10  \n",
       "93          0   50.00  \n",
       "124         0  949.00  \n",
       "...       ...     ...  \n",
       "4120171    23    3.80  \n",
       "4120202    23   67.00  \n",
       "4120233    23  948.00  \n",
       "4120264    23    1.00  \n",
       "4120295    23    0.00  \n",
       "\n",
       "[4120296 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.sort_values(by=['Hora', 'Fecha'], ascending=True, inplace=True)\n",
    "datos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iabd_time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
